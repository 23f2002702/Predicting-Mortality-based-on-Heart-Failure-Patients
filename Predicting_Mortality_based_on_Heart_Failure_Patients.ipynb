{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting Mortality based on Heart Failure Patients**\n",
        "\n",
        "This project focuses on predicting mortality outcomes among heart failure patients using a combination of machine learning algorithms. The dataset undergoes preprocessing followed by training and evaluation using several classification models:\n",
        "\n",
        "\n",
        ">The module is divided into the following steps:\n",
        "\n",
        "\n",
        "1.   Import Libraries\n",
        "2.   Load Dataset\n",
        "3.   Preprocessing\n",
        "1.   Support Vector Machine(SVM)\n",
        "1.   Decision Tree\n",
        "2.   Gaussian Naive Bayes (GNB)\n",
        "3.   Random Forest Classification (RF)\n",
        "4.   XGBoost Classification (XGB)\n",
        "5.   AdaBoost Classification\n",
        "6.   Artificial Neural Network (ANN)\n",
        "\n",
        "# **Extras** #\n",
        "1.   Finding the worst Classification Algorithm using ROC AUC Score\n",
        "1.   Sampling using SMOTE with the worst Classification Algorithm\n",
        "2.   Using Explainable AI (Lime) to explain why one specific prediction was made (using misclassified sample).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eqNoVGANSn3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn lime xgboost\n"
      ],
      "metadata": {
        "id": "MKIQOivTLktV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Importing necessary libraries\n",
        "\n",
        "# Data and Preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Handling Imbalanced Data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ANN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# Explainable AI\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "rqz2h1ctG3PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 : Load the dataset and check the values\n",
        "df = pd.read_csv(\"heart_failure_clinical_records.csv\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "wjl9bV-CRQQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "qS45HqvJWSLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df.corr(),annot=True,cmap='Greens', fmt=\".2f\", linewidths=0.5, cbar=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2nuAnl3Wu65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['#FFF000', '#FF0000']\n",
        "plt.figure(figsize=(25,10))\n",
        "days_of_week = sns.countplot(x=\"age\", data=df, hue = 'DEATH_EVENT', palette = cols)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FYhB-baMXbZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Preprocessing\n",
        "X = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "# Hold out a final test set\n",
        "X_trainval, X_finaltest, y_trainval, y_finaltest = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_trainval_scaled = scaler.fit_transform(X_trainval)\n",
        "X_finaltest_scaled = scaler.transform(X_finaltest)\n"
      ],
      "metadata": {
        "id": "NY4fET8TPvJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine**#"
      ],
      "metadata": {
        "id": "1sJus84CthUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(probability=True, kernel='rbf', random_state=42)\n",
        "svm_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "svm_preds = svm_model.predict(X_finaltest_scaled)\n",
        "svm_probs = svm_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"===== SVM Classification Report =====\")\n",
        "print(classification_report(y_finaltest, svm_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, svm_probs))\n",
        "\n"
      ],
      "metadata": {
        "id": "MyHZy5lRROmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Classifier** #\n"
      ],
      "metadata": {
        "id": "W7m5BiDYRS-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "dt_preds = dt_model.predict(X_finaltest_scaled)\n",
        "dt_probs = dt_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n===== Decision Tree Classification Report =====\")\n",
        "print(classification_report(y_finaltest, dt_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, dt_probs))\n"
      ],
      "metadata": {
        "id": "jiigw1aBRCtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gaussian Naive Bayes** #"
      ],
      "metadata": {
        "id": "Yl6r3jhjRcTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "gnb_preds = gnb_model.predict(X_finaltest_scaled)\n",
        "gnb_probs = gnb_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n===== Gaussian Naive Bayes Classification Report =====\")\n",
        "print(classification_report(y_finaltest, gnb_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, gnb_probs))\n"
      ],
      "metadata": {
        "id": "L120cGUsRPgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Classification** #"
      ],
      "metadata": {
        "id": "UJqpb-G-V-PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "rf_preds = rf_model.predict(X_finaltest_scaled)\n",
        "rf_probs = rf_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n===== Random Forest Classification Report =====\")\n",
        "print(classification_report(y_finaltest, rf_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, rf_probs))\n"
      ],
      "metadata": {
        "id": "97TQPHZWSwpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost Classification** #"
      ],
      "metadata": {
        "id": "QOTnwpr7WBtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "xgb_preds = xgb_model.predict(X_finaltest_scaled)\n",
        "xgb_probs = xgb_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n===== XGBoost Classification Report =====\")\n",
        "print(classification_report(y_finaltest, xgb_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, xgb_probs))\n"
      ],
      "metadata": {
        "id": "ixPl4KiRWBfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost Classification** #"
      ],
      "metadata": {
        "id": "CTXdN8rMWPEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada_model.fit(X_trainval_scaled, y_trainval)\n",
        "\n",
        "ada_preds = ada_model.predict(X_finaltest_scaled)\n",
        "ada_probs = ada_model.predict_proba(X_finaltest_scaled)[:, 1]\n",
        "\n",
        "print(\"\\n===== AdaBoost Classification Report =====\")\n",
        "print(classification_report(y_finaltest, ada_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, ada_probs))\n"
      ],
      "metadata": {
        "id": "qweR12UbWLP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Artificial Neural Network** #"
      ],
      "metadata": {
        "id": "MaFGJVBNtPsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping to avoid overfitting\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=30,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Define the model\n",
        "ANN_model = Sequential()\n",
        "ANN_model.add(Dense(32, input_dim=12, activation='relu', kernel_initializer='he_uniform'))\n",
        "ANN_model.add(Dense(8, activation='relu', kernel_initializer='he_uniform'))\n",
        "ANN_model.add(Dropout(0.25))\n",
        "ANN_model.add(Dense(8, activation='relu', kernel_initializer='he_uniform'))\n",
        "ANN_model.add(Dropout(0.25))\n",
        "ANN_model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform'))\n"
      ],
      "metadata": {
        "id": "_vP0ccg2tOKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "ANN_model.summary()"
      ],
      "metadata": {
        "id": "mmNM_05-Cox8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ANN_model.fit(\n",
        "    X_trainval_scaled,\n",
        "    y_trainval,\n",
        "    validation_split=0.25,\n",
        "    epochs=100,\n",
        "    batch_size=25,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "XxlKEzrEDzen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Plot Loss Curves ===\n",
        "history_df = pd.DataFrame(history.history)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_df['loss'], label='Train Loss')\n",
        "plt.plot(history_df['val_loss'], label='Val Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "UChpWnhAGkdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Plot Accuracy Curves ===\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_df['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_df['val_accuracy'], label='Val Accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4yah7h47K7R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Final Evaluation on True Test Set ===\n",
        "y_ann_probs = ANN_model.predict(X_finaltest_scaled)\n",
        "y_ann_preds = (y_ann_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n===== ANN Classification Report (Final Test Set) =====\")\n",
        "print(classification_report(y_finaltest, y_ann_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_finaltest, y_ann_probs))"
      ],
      "metadata": {
        "id": "VM024tdtNH5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GlmfySN7YTeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So we can see that XGBoost ad Random Forest Classification gives us the highest ROC AUC Score for the given dataset. Now the dataset is not perfectly sampled i.e. The numner of **YES** and **NO** for **Death_Event** are not equal. Thus we'll apply SMOTE to balance the class and then work with Gaussian Naive Bayes and AdaBoost to see if the changes.\n",
        "\n"
      ],
      "metadata": {
        "id": "xYcEs9p-Uj5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Resample features and target\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Train-test split after SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "KMui835MXZE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colors\n",
        "cols = ['#FFF000', '#FF0000']\n",
        "\n",
        "# Create a new DataFrame from the resampled data\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
        "df_resampled['DEATH_EVENT'] = y_resampled\n",
        "\n",
        "# Plot side-by-side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Before SMOTE\n",
        "ax1 = sns.countplot(x=\"DEATH_EVENT\", data=df, ax=axes[0])\n",
        "axes[0].set_title(\"Before SMOTE\")\n",
        "for bar, color in zip(ax1.patches, cols):\n",
        "    bar.set_color(color)\n",
        "\n",
        "# After SMOTE\n",
        "ax2 = sns.countplot(x=\"DEATH_EVENT\", data=df_resampled, ax=axes[1])\n",
        "axes[1].set_title(\"After SMOTE\")\n",
        "for bar, color in zip(ax2.patches, cols):\n",
        "    bar.set_color(color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zla7lYLSXBYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Scaling after SMOTE and train-test split\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the GaussianNB model\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train, y_train)\n",
        "\n",
        "#  Make predictions and probability estimates\n",
        "gnb_preds = gnb_model.predict(X_test)\n",
        "gnb_probs = gnb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n===== Gaussian Naive Bayes Classification Report =====\")\n",
        "print(classification_report(y_test, gnb_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, gnb_probs))"
      ],
      "metadata": {
        "id": "VnicLUUMYgcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the AdaBoost model\n",
        "ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and probabilities\n",
        "ada_preds = ada_model.predict(X_test)\n",
        "ada_probs = ada_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\n===== AdaBoost Classification Report =====\")\n",
        "print(classification_report(y_test, ada_preds))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, ada_probs))"
      ],
      "metadata": {
        "id": "d_OOchSUZOun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Thus we can see applying SMOTE increased the ROC AUC Score for Gaussian Naive Bayes by 0.002 and for AdaBoost by 0.9.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ouKXeulCZxKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally using LIME helps in understanding why a particular prediction was made. LIME doesn‚Äôt explain the whole model ‚Äî it explains why the model made a decision for one particular sample (a local explanation).\n",
        "\n",
        "### In this case I found the misclassified samples and used LIME to find which features made the model give a wrong prediction.\n",
        "\n",
        "###The bars and values show which features pushed the prediction towards **‚ÄúSurvived‚Äù (blue)** or toward **‚ÄúDied‚Äù (orange)**\n",
        "\n",
        "### The values in the centre left table for each bar gives the magnitude of contribution of that feature interval to the final prediction.\n",
        "\n",
        "\n",
        "\n",
        "# **üü¶ Blue bars = Pushed prediction toward ‚ÄúSurvived‚Äù**\n",
        "\n",
        "\n",
        "# **üüß Orange bars = Pushed prediction toward ‚ÄúDied‚Äù** #\n",
        "\n"
      ],
      "metadata": {
        "id": "U2z3EzCrbwZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explainable AI (EAI)** #"
      ],
      "metadata": {
        "id": "M13wzLQ5Zjch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "feature_names = [\n",
        "    'age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction',\n",
        "    'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium',\n",
        "    'sex', 'smoking', 'time'\n",
        "]\n",
        "\n",
        "# LIME explainer\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_trainval_scaled,\n",
        "    feature_names=feature_names,\n",
        "    class_names=['Survived', 'Died'],\n",
        "    mode='classification',\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "# Wrapper to match ANN's probability shape\n",
        "def predict_proba_wrapper(x):\n",
        "    probs = ANN_model.predict(x)\n",
        "    return np.hstack([1 - probs, probs])\n"
      ],
      "metadata": {
        "id": "2AFBPhkRkGig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten predictions just to be safe\n",
        "y_pred_binary = y_ann_preds.flatten()\n",
        "\n",
        "# Find indices where predicted not equal to actual\n",
        "misclassified_indices = np.where(y_pred_binary != y_finaltest.to_numpy())[0]\n",
        "\n",
        "print(f\"Total misclassified samples: {len(misclassified_indices)}\")\n",
        "print(\"Indices of misclassified samples:\", misclassified_indices)\n",
        "\n",
        "for i in misclassified_indices:\n",
        "    print(f\"\\n--- Misclassified Sample #{i} ---\")\n",
        "    print(f\"True Label     : {y_finaltest.iloc[i]}\")\n",
        "    print(f\"Predicted Label: {y_pred_binary[i]}\")\n",
        "    print(f\"Features (scaled):\\n{X_finaltest_scaled[i]}\")\n",
        "\n",
        "# Explain with LIME\n",
        "    lime_exp = lime_explainer.explain_instance(\n",
        "        X_finaltest_scaled[i],\n",
        "        predict_proba_wrapper,\n",
        "        num_features=10\n",
        "    )\n",
        "    lime_exp.show_in_notebook()"
      ],
      "metadata": {
        "id": "dLf9MeITaIOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
